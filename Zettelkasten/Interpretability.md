Created on: 11-07-2025 00:15, note by Youssef Okeil
Status: #idea
Tags: #AI/Safety/Interpretability 
# Interpretability

### Definition
it's very hard to come up with a proper definition for interpretability.
When we say "interpretability", it's usually interchangeable with other things that evaluate, debug & describe the model.

### ![[The Need for Interpretability#The Need for Interpretability]]
### Objection to Interpretability:
- mechanistic interpretability may not always be the best way to go.
	1. imagine you overcome bias in your model, by first identifying the set of neurons or weights that lead to that bias. The hypothesis however was not perfect, and now the bias is even bigger.
	2. If instead you notice that he dataset has a lack of black people. By making the data more representative, the problem is fixed.
	- Moral of the story, we shouldn't privilege some methods over others. 
- Interpretability is a means to an end
	- The word interpretability is almost entirely interchangeable with describing, evaluating, debugging.
- From an engineering perspective, it's important  to grade different classes of solution on different curves. --> Any practical approach must focus on eventually producing actionable insights to help us better design, develop or deploy models. 




-----------------
# References