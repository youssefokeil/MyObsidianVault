Created on: 04-03-2025 16:28
Status: #idea
Tags: #AI/evals #AI/Governance #AI/Safety 
### Robustness of Preparedness Frameworks
- We must ensure that risk mitigations work. This is the most important and difficulty part of the PF.
### OpenAI
- If they reach "critical" pre-mitigation risk, they ensure that they will do the right mitigations to reach "high" post-mitigation risk
- This is a bit challenging as the "critical" threshold is too high as they mention the possibility that the model will be able to self ex-filtrate.
- Model being capable of  [[self ex-filtration]] means that most risk mitigations are ineffective.
### Anthropic
- ASL-3 threshold which means that access to the model will substantially increase risk of catastrophic misuse.
- Their mitigations that they'll harden their security so that non-state actors will not be able to ex-filtrate their weights.
- A more conservative thing is to make sure than state and non-state actors will not be able to steal their weights.



-----------------
# References