Created on: 04-03-2025 17:32
Status: #idea
Tags: #ai_gov #AI_eval #ai_safety 
### Transparency of Evals in PFs
- Publishing evaluations and mitigations is an important tool for holding developers accountable to their PF commitments.
- However too much transparency can be exploited by malicious actors.
### Anthropic
- has a balanced approach to sharing evals
- "\[p]ublicly share evaluation results after model deployment where possible, in some cases in the initial model card, in other cases with a delay if it serves a broad safety intere"
### OpenAI
- Doesn't commit to sharing Model Scorecards
- But they have published research on whether their models aid creation of biological threats.



-----------------
# References