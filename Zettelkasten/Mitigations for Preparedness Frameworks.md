Created on: 04-03-2025 16:14
Status: #idea
Tags: #ai_gov #AI_eval #ai_safety 
### Risk Mitigations
Risk mitigations may look like this:
- restricting development or deployment of models at different risk thresholds
- Cybersecurity measures to prevent stealing of model weights
- Tiered access to models 
- Interacting with models in restricted environments
- Deleting model weights
### Anthropic
_ASL-2 models like Claude 2_
- publishing model cards
- providing a vulnerability reporting mechanism
_ASL-3_
- Limit access to training techniques and model hyperparameters
- Implement measures to harden their security
### OpenAI
- _Restricts deployment_ of models such that "only models with a post-mitigation score of medium to below can be deployed"
- _Restricts development_ of models with risks of high or below
- 

-----------------
# References