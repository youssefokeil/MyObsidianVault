Created on: 06-10-2025 17:11, note by Youssef Okeil
Status: #idea
Tags: #AI/reinforcement-learning 
# Reward Signal
> defines the goal of the reinforcement learning problem. With every action the agent takes, the environment returns a reward to the agent. The intensity of this reward signal, signifies whether the agent took a good decision or not. 

The reward depends on the current action $A_t$ and the current state $S_t$ of the agent.

The agent shouldn't be able to alter the process that does this.



-----------------
# References
[[Reinforcement-Learning by Sutton & Barto]]